{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, 'models')\n",
    "sys.path.insert(0, 'utils')\n",
    "sys.path.insert(1, '../dsvae/yukun_disentanglement_lib/')\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import yukun_disentanglement_lib\n",
    "import celeba\n",
    "import numpy as np\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import argparse\n",
    "from plotting_utils import plot_pytorch_images\n",
    "from misc import merge\n",
    "\n",
    "from dsvae_model import DSVAE, loss_function\n",
    "from datasets import DSVAE_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--num_datapoints\", help=\"num datapoints\", default=100000, type=int)\n",
    "parser.add_argument(\"--z_dim\", help=\"z dimension\", default=85, type=int)\n",
    "parser.add_argument(\"--device\", help=\"gpu id\", default=1, type=int)\n",
    "parser.add_argument(\"--nb_epochs\", help=\"number of epochs\", default=500, type=int)\n",
    "parser.add_argument(\"--start_epoch\", help=\"epoch to start training from (requires checkpoints)\", default=0, type=int)\n",
    "parser.add_argument(\"--save_interval\", help=\"epochs to save model\", default=10, type=int)\n",
    "parser.add_argument(\"--run_seed\", help=\"run seed of TCVAE\", default=100, type=int)\n",
    "parser.add_argument(\"--lr\", help=\"learning rate\", default=.0001, type=float)\n",
    "parser.add_argument(\"--batch_size\", help=\"batch size\", default=100, type=int)\n",
    "args = parser.parse_args([])\n",
    "\n",
    "num_datapoints=args.num_datapoints\n",
    "\n",
    "log = False\n",
    "if log:\n",
    "    wandb.init(project=\"pytorch_dsvae\", name=\"celeba_{}\".format(num_datapoints))\n",
    "    wandb.config.update(args)\n",
    "\n",
    "device = args.device\n",
    "print(\"z_dim: {}\".format(args.z_dim))\n",
    "print(\"GPU: {}\".format(device))\n",
    "print(\"start_epoch: {}\".format(args.start_epoch))\n",
    "print(\"save_interval: {}\".format(args.save_interval))\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[args.device], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = False\n",
    "save = True\n",
    "num_y_samples = 10\n",
    "tf.set_random_seed(1)\n",
    "classifier_url = '../dsvae/tcvae_models/celeba/train_output/100k/d_15_b_15_{}/tfhub/'.format(100)\n",
    "num_samples=num_datapoints\n",
    "if not load:\n",
    "    dta = celeba.CelebA(celeba_path=\"../dsvae/yukun_disentanglement_lib/img_align_celeba\", num_samples=num_samples)\n",
    "    ys = np.float32(np.empty((num_samples, num_y_samples, 64, 64,3)))\n",
    "    with hub.eval_function_for_module(classifier_url) as f:\n",
    "        for j in range(num_y_samples):\n",
    "            y = []\n",
    "            for i in range(10):\n",
    "                x = np.float32(dta.images[i*int(num_samples/10):(i+1)*int(num_samples/10)])\n",
    "                y.append(f(dict(images=x), signature=\"reconstructions\", as_dict=True)[\"images\"]) \n",
    "            ys[:,j] = np.float32(np.concatenate(y,axis=0))\n",
    "    inputs = np.float32(dta.images)\n",
    "    targets = np.float32(ys)\n",
    "    del dta\n",
    "    del classifier\n",
    "    if save:\n",
    "        np.save('saved_data/inputs_{}_sample'.format(num_samples), inputs)\n",
    "        np.save('saved_data/targets_{}_sample'.format(num_samples), targets)     \n",
    "else:  \n",
    "    inputs = np.load('saved_data/inputs_{}_sample.npy'.format(num_samples))\n",
    "    targets = np.load('saved_data/targets_{}_sample.npy'.format(num_samples))\n",
    "    \n",
    "torch_inputs = torch.from_numpy(inputs).permute(0,3,1,2)\n",
    "torch_targets = torch.from_numpy(targets).permute(0,1,4,2,3)\n",
    "torch_dataset = DSVAE_DATA(torch_inputs, torch_targets)\n",
    "torch_data_loader = torch.utils.data.DataLoader(torch_dataset, batch_size=args.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiating and Training DSVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device != -1 and device is not None:\n",
    "    dsvae = DSVAE(z_dim=85, y_shape=[3,64,64], input_shape=[3,64,64], device=args.device)\n",
    "    dsvae.to(device)\n",
    "else:\n",
    "    dsvae = DSVAE(z_dim=85, y_shape=[3,64,64], input_shape=[3,64,64], device=None)\n",
    "optimizer = torch.optim.Adam(params=dsvae.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dsvae.train()\n",
    "normal = torch.distributions.Normal(0,1)\n",
    "print(\"Training for {} epochs...\".format(1500))\n",
    "for n in range(0, 1500):\n",
    "    for (i, X) in enumerate(torch_data_loader):\n",
    "        x = X[0]\n",
    "        y_all = X[1]\n",
    "        rand_int = np.random.randint(0,num_y_samples)\n",
    "        y = y_all[:,rand_int]\n",
    "        if dsvae.cuda:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x_hat, z_mu, z_var = dsvae(x, y)\n",
    "        loss, recon_loss, kl_loss = loss_function(x_hat, x, z_mu, z_var)\n",
    "        if log:\n",
    "            wandb.log({'loss':loss})\n",
    "            wandb.log({'recon_loss':recon_loss})\n",
    "            wandb.log({'kl_loss':kl_loss})\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if n%20 ==0:\n",
    "        dsvae.eval() #evaluate model\n",
    "        z_noise = normal.sample((x.shape[0],85))\n",
    "        z_zeros = torch.zeros((x.shape[0],85))\n",
    "        if dsvae.cuda:\n",
    "            z_noise = z_noise.to(device)\n",
    "            z_zeros = z_zeros.to(device)\n",
    "        x_hat_noise = dsvae.decode(z_noise, y)\n",
    "        x_hat_zeros = dsvae.decode(z_zeros, y)\n",
    "        \n",
    "        fig = plot_pytorch_images(x_hat_zeros[:5], num_images=5, title='Zeros z, num epochs: {}'.format(n))\n",
    "        if log:\n",
    "            wandb.log({'Zeros z':fig})\n",
    "            \n",
    "        fig = plot_pytorch_images(x_hat_noise[:5], num_images=5, title='Std. Normal z, num epochs: {}'.format(n))\n",
    "        if log:\n",
    "            wandb.log({'Std. Normal z':fig})\n",
    "            \n",
    "        fig = plot_pytorch_images(x_hat[:5], num_images=5, title='Encoder z, num epochs: {}'.format(n))\n",
    "        if log:\n",
    "            wandb.log({'Encoder z':fig})\n",
    "            \n",
    "        fig = plot_pytorch_images(x[:5], num_images=5, title='x, num epochs: {}'.format(n))\n",
    "        if log:\n",
    "            wandb.log({'x':fig})\n",
    "\n",
    "        fig = plot_pytorch_images(torch.sigmoid(y[:5]), num_images=5, title='y, num epochs: {}'.format(n))\n",
    "        if log:\n",
    "            wandb.log({'y':fig})   \n",
    "        dsvae.train() #back to training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peforming Traversals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model=False\n",
    "if load_model:\n",
    "    dsvae = torch.load(\"dsvae_model_100k_more\")\n",
    "dsvae = dsvae.cpu()\n",
    "dsvae.device = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_url = '../dsvae/tcvae_models/celeba/train_output/100k/d_15_b_15_{}/tfhub/'.format(100)\n",
    "classifier = hub.Module(classifier_url)\n",
    "dta = celeba.CelebA(celeba_path=\"../dsvae/yukun_disentanglement_lib/img_align_celeba\", num_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "import os\n",
    "from yukun_disentanglement_lib.data.ground_truth import named_data\n",
    "from yukun_disentanglement_lib.utils import results\n",
    "from yukun_disentanglement_lib.visualize import visualize_util\n",
    "from yukun_disentanglement_lib.visualize.visualize_irs import vis_all_interventional_effects\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from six.moves import range\n",
    "from tensorflow import gfile\n",
    "import gin.tf\n",
    "from yukun_disentanglement_lib.visualize.visualize_model import latent_traversal_1d_multi_dim, sigmoid, tanh, latent_traversal_1d_multi_dim_dsvae\n",
    "\n",
    "output_dir = 'visualize_output_sample'\n",
    "print(output_dir)\n",
    "overwrite=True\n",
    "num_animations=15\n",
    "num_frames=32\n",
    "fps=10\n",
    "num_points_irs=10000\n",
    "# Create the output directory if necessary.\n",
    "if tf.gfile.IsDirectory(output_dir):\n",
    "    if overwrite:\n",
    "        tf.gfile.DeleteRecursively(output_dir)\n",
    "    else:\n",
    "        raise ValueError(\"Directory already exists and overwrite is False.\")\n",
    "\n",
    "gin_config_file = os.path.join(model_dir, \"results\", \"gin\", \"train.gin\")\n",
    "print(gin_config_file)\n",
    "gin_dict = results.gin_dict(gin_config_file)\n",
    "\n",
    "num_pics = 32\n",
    "module_path = os.path.join(model_dir, \"tfhub\")\n",
    "dsvae.eval()\n",
    "with hub.eval_function_for_module(classifier_url) as f:\n",
    "    # Save reconstructions.\n",
    "    random_state = np.random.RandomState(2)\n",
    "    real_pics = dta.sample_observations(num_pics, random_state)\n",
    "    raw_pics = f(dict(images=real_pics), signature=\"reconstructions\", as_dict=True)[\"images\"]\n",
    "    pics = sigmoid(raw_pics)\n",
    "\n",
    "    torch_real_pics = torch.from_numpy(real_pics).permute(0,3,1,2).float()\n",
    "    torch_raw_pics = torch.from_numpy(raw_pics).permute(0,3,1,2).float()\n",
    "    \n",
    "    x_hat, _,_ = dsvae(torch_real_pics, torch_raw_pics)\n",
    "    x_hat_numpy = x_hat.detach().permute(0,2,3,1).numpy()\n",
    "\n",
    "    paired_pics = np.concatenate((real_pics, pics), axis=2)\n",
    "    paired_pics = [paired_pics[i, :, :, :] for i in range(paired_pics.shape[0])]\n",
    "    results_dir = os.path.join(output_dir, \"reconstructions\")\n",
    "    if not gfile.IsDirectory(results_dir):\n",
    "        gfile.MakeDirs(results_dir)\n",
    "    visualize_util.grid_save_images(\n",
    "        paired_pics, os.path.join(results_dir, \"reconstructions.jpg\"))\n",
    "    paired_pics = np.concatenate((real_pics, pics, x_hat_numpy), axis=2)\n",
    "    paired_pics = [paired_pics[i, :, :, :] for i in range(paired_pics.shape[0])]\n",
    "    results_dir = os.path.join(output_dir, \"reconstructions\")\n",
    "    if not gfile.IsDirectory(results_dir):\n",
    "        gfile.MakeDirs(results_dir)\n",
    "    visualize_util.grid_save_images(\n",
    "        paired_pics, os.path.join(results_dir, \"reconstructions_dsvae.jpg\"))\n",
    "    print(\"finished reconstructions\")\n",
    "    \n",
    "    # Save samples\n",
    "    def _decoder(latent_vectors):\n",
    "        return f(\n",
    "          dict(latent_vectors=latent_vectors),\n",
    "          signature=\"decoder\",\n",
    "          as_dict=True)[\"images\"]\n",
    "    num_latent = int(gin_dict[\"encoder.num_latent\"])\n",
    "    num_pics = 64\n",
    "    random_codes = random_state.normal(0, 1, [num_pics, num_latent])\n",
    "    pics = sigmoid(_decoder(random_codes))\n",
    "    results_dir = os.path.join(output_dir, \"sampled\")\n",
    "    if not gfile.IsDirectory(results_dir):\n",
    "        gfile.MakeDirs(results_dir)\n",
    "    visualize_util.grid_save_images(pics,\n",
    "                                    os.path.join(results_dir, \"samples.jpg\"))\n",
    "    print(\"finished samples\")\n",
    "    \n",
    "    # Save latent traversals.\n",
    "    input_images = dta.sample_observations(num_pics, random_state)\n",
    "    result = f(dict(images=input_images), signature=\"gaussian_encoder\", as_dict=True)\n",
    "    means = result[\"mean\"]\n",
    "    logvars = result[\"logvar\"]\n",
    "    raw_pics = _decoder(means)\n",
    "    torch_real_pics = torch.from_numpy(input_images).permute(0,3,1,2)\n",
    "    torch_raw_pics = torch.from_numpy(raw_pics).permute(0,3,1,2)\n",
    "    x_hat, z_mu, z_var = dsvae(torch_real_pics, torch_raw_pics)\n",
    "    results_dir = os.path.join(output_dir, \"traversals\")\n",
    "    if not gfile.IsDirectory(results_dir):\n",
    "        gfile.MakeDirs(results_dir)\n",
    "    for i in range(10):\n",
    "        dsvae_pics = latent_traversal_1d_multi_dim_dsvae(dsvae, z_mu[i, :], _decoder, means[i, :])\n",
    "        pics = sigmoid(latent_traversal_1d_multi_dim(_decoder, means[i, :], None)) \n",
    "        \n",
    "        file_name = os.path.join(results_dir, \"traversals{}.jpg\".format(i))\n",
    "        visualize_util.grid_save_images([pics], file_name)\n",
    "        \n",
    "        file_name = os.path.join(results_dir, \"traversals_dsvae{}.jpg\".format(i))\n",
    "        visualize_util.grid_save_images([dsvae_pics], file_name)\n",
    "    print(\"finished traversals\")\n",
    "        \n",
    "    # Save the latent traversal animations.\n",
    "    results_dir = os.path.join(output_dir, \"animated_traversals\")\n",
    "    if not gfile.IsDirectory(results_dir):\n",
    "        gfile.MakeDirs(results_dir)\n",
    "    # Save latent traversal animations as a grid\n",
    "    results_dir_grid = os.path.join(output_dir, \"traversals_grid\")\n",
    "    if not gfile.IsDirectory(results_dir_grid):\n",
    "        gfile.MakeDirs(results_dir_grid)\n",
    "    # Cycle through quantiles of a standard Gaussian.\n",
    "    for i, base_code in enumerate(means[:num_animations]):\n",
    "        images = []\n",
    "        y_traversal_images = []\n",
    "        #print(base_code.shape) #base_code shape is (8, )\n",
    "        for j in range(base_code.shape[0]):\n",
    "            code = np.repeat(np.expand_dims(base_code, 0), num_frames, axis=0) #Repeat c for num_frames\n",
    "            code[:, j] = visualize_util.cycle_gaussian(base_code[j], num_frames) #Get traversal values for 1 dim\n",
    "            y_traversal = _decoder(code) #y_traversal[0] corresponds to the orginal image\n",
    "            images.append(np.array(sigmoid(_decoder(code))))\n",
    "            \n",
    "            torch_base_x = torch.from_numpy(input_images[i]).float().unsqueeze(0).permute(0,3,1,2)\n",
    "            torch_base_y = torch.from_numpy(y_traversal[0]).float().unsqueeze(0).permute(0,3,1,2)\n",
    "            torch_y_traversal = torch.from_numpy(y_traversal).permute(0,3,1,2).float()\n",
    "            \n",
    "            x_hat, z_mu, z_var = dsvae(torch_base_x, torch_base_y)\n",
    "            z_mu_repeat = z_mu.repeat((len(y_traversal),1))\n",
    "            x_hat_traversal = dsvae.decode(z_mu_repeat, torch_y_traversal)\n",
    "            x_hat_traversal = x_hat_traversal.detach().permute(0,2,3,1).numpy()\n",
    "            y_traversal_images.append(x_hat_traversal)\n",
    "            \n",
    "            inds = np.arange(0, 32, 4)\n",
    "            num_images = len(inds)\n",
    "            y_xbar = np.concatenate((images[j][inds], y_traversal_images[j][inds]))\n",
    "            img = merge(y_xbar, [2, num_images])\n",
    "            plt.figure(figsize=(16,16))\n",
    "            plt.imshow(img)\n",
    "            plt.gray()\n",
    "            plt.axis('off')\n",
    "            plt.savefig(os.path.join(results_dir_grid, \"std_gaussian_cycle_latent_%d_sample_%d.jpg\" % (j, i)))\n",
    "            plt.show()\n",
    "        filename = os.path.join(results_dir, \"std_gaussian_cycle%d.gif\" % i)\n",
    "        visualize_util.save_animation(np.array(images), filename, fps)\n",
    "        filename = os.path.join(results_dir, \"twovae_zmean_repeat_std_gaussian_cycle%d.gif\" % i)\n",
    "        visualize_util.save_animation(y_traversal_images, filename, fps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
