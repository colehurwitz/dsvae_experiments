{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, 'models')\n",
    "sys.path.insert(0, 'utils')\n",
    "# from yukun_disentanglement_lib.data.ground_truth import celeba, celebaHR\n",
    "from dsvae_model_large_HR_no_enc_no_y_no_in import DSVAELHR, loss_function\n",
    "from datasets import DATA_HR\n",
    "import celebaHR\n",
    "import numpy as np\n",
    "import time, math\n",
    "from misc import merge\n",
    "import argparse\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/churwitz/pytorch_dsvae_hr/runs/6i4mmvow\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
       "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log = True\n",
    "if log:\n",
    "    wandb.init(project=\"pytorch_dsvae_hr\", name=\"celeba_dsvae_10k_HR_no_enc_no_y_no_in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.29 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_dim: 85\n",
      "GPU: 1\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--z_dim\", help=\"z dimension\", default=85, type=int)\n",
    "parser.add_argument(\"--device\", help=\"gpu id\", default=1, type=int)\n",
    "parser.add_argument(\"--nb_epochs\", help=\"number of epochs\", default=500, type=int)\n",
    "parser.add_argument(\"--lr\", help=\"learning rate\", default=.0001, type=float)\n",
    "parser.add_argument(\"--batch_size\", help=\"batch size\", default=100, type=int)\n",
    "args = parser.parse_args([])\n",
    "\n",
    "if log:\n",
    "    wandb.config.update(args)\n",
    "\n",
    "device = args.device\n",
    "print(\"z_dim: {}\".format(args.z_dim))\n",
    "print(\"GPU: {}\".format(device))\n",
    "\n",
    "num_samples=12000\n",
    "path_to_celebA = \"../dsvae/yukun_disentanglement_lib/img_align_celeba\"\n",
    "dtahr = celebaHR.CelebAHR(celeba_path=path_to_celebA, num_samples=num_samples, res=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_hr = np.float32(dtahr.images[:10000])\n",
    "validation_hr = np.float32(dtahr.images[10000:])\n",
    "torch_inputs_hr = torch.from_numpy(inputs_hr).permute(0,3,1,2)\n",
    "torch_validation_hr = torch.from_numpy(validation_hr).permute(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dataset = DATA_HR(torch_inputs_hr)\n",
    "torch_data_loader = torch.utils.data.DataLoader(torch_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "torch_validation_dataset = DATA_HR(torch_validation_hr)\n",
    "torch_validation_loader = torch.utils.data.DataLoader(torch_validation_dataset, batch_size=args.batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pytorch_images(images, num_images=5, title=\"\"):\n",
    "    images = images.detach()\n",
    "    if images.is_cuda:\n",
    "        images = images.cpu()\n",
    "    images = images.permute(0,2,3,1)\n",
    "    img = np.expand_dims(images,0)\n",
    "    img = merge(img[0],[1,num_images])\n",
    "    fig = plt.figure(figsize=(8*max(1, num_images-2),8))\n",
    "    plt.imshow(img)\n",
    "    plt.gray()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.device != -1:\n",
    "    dsvae = DSVAELHR(z_dim=85, device=args.device)\n",
    "    dsvae.to(device)\n",
    "else:\n",
    "    dsvae = DSVAELHR(z_dim=85, device=None)\n",
    "optimizer = torch.optim.Adam(params=dsvae.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the DSVAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dsvae.train()\n",
    "normal = torch.distributions.Normal(0,1)\n",
    "print(\"Training for {} epochs...\".format(1500))\n",
    "for n in range(0, 1000):\n",
    "    train_loss = 0\n",
    "    train_recon_loss = 0\n",
    "    train_kl_loss = 0\n",
    "    num_examples = 0\n",
    "    for (i, X) in enumerate(torch_data_loader):\n",
    "        x_hr = X\n",
    "        if dsvae.cuda:\n",
    "            x_hr = x_hr.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x_hr_hat, z_mu, z_var = dsvae(x_hr)\n",
    "        loss, recon_loss, kl_loss = loss_function(x_hr_hat, x_hr, z_mu, z_var)\n",
    "        train_loss += loss.item()\n",
    "        train_recon_loss += recon_loss.item()\n",
    "        train_kl_loss += kl_loss.item()\n",
    "        num_examples += x_hr.shape[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if log:\n",
    "        wandb.log({'train_loss':train_loss/num_examples})\n",
    "        wandb.log({'train_recon_loss':train_recon_loss/num_examples})\n",
    "        wandb.log({'train_kl_loss':train_kl_loss/num_examples})\n",
    "    \n",
    "    dsvae.eval()\n",
    "    validation_loss = 0\n",
    "    validation_recon_loss = 0\n",
    "    validation_kl_loss = 0\n",
    "    num_examples = 0\n",
    "    for (j, X) in enumerate(torch_validation_loader):\n",
    "        x_hr = X\n",
    "        if dsvae.cuda:\n",
    "            x_hr = x_hr.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x_hr_hat, z_mu, z_var = dsvae(x_hr)\n",
    "        loss, recon_loss, kl_loss = loss_function(x_hr_hat, x_hr, z_mu, z_var)\n",
    "        validation_loss += loss.item()\n",
    "        validation_recon_loss += recon_loss.item()\n",
    "        validation_kl_loss += kl_loss.item()\n",
    "        num_examples += x_hr.shape[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if log:\n",
    "        wandb.log({'validation_loss':validation_loss/num_examples})\n",
    "        wandb.log({'validation_recon_loss':validation_recon_loss/num_examples})\n",
    "        wandb.log({'validation_kl_loss':validation_kl_loss/num_examples})\n",
    "\n",
    "    if n%50 ==0:\n",
    "        dsvae.eval() #evaluate model\n",
    "        rand_indices = np.random.randint(0,len(torch_validation_dataset), 5)\n",
    "        z_noise = normal.sample((5,85))\n",
    "        z_zeros = torch.zeros((5,85))\n",
    "        x_hr = torch_validation_dataset[rand_indices]\n",
    "        \n",
    "        if dsvae.cuda:\n",
    "            z_noise = z_noise.to(device)\n",
    "            z_zeros = z_zeros.to(device)\n",
    "            x_hr = x_hr.to(device)\n",
    "            \n",
    "        x_hat_noise = dsvae.decode(z_noise)\n",
    "        x_hat_zeros = dsvae.decode(z_zeros)\n",
    "        x_hr_hat, _, _ = dsvae(x_hr)\n",
    "        \n",
    "        fig = plot_pytorch_images(x_hat_zeros, num_images=5, title='Zeros z, num epochs: {}'.format(n))\n",
    "        if log:\n",
    "            wandb.log({'Sample from zero':fig})\n",
    "            \n",
    "        fig = plot_pytorch_images(x_hat_noise, num_images=5, title='Std. Normal z, num epochs: {}'.format(n))\n",
    "        if log:\n",
    "            wandb.log({'Samples from prior':fig})\n",
    "            \n",
    "        fig = plot_pytorch_images(x_hr_hat, num_images=5, title='Encoder z, num epochs: {}'.format(n))\n",
    "        if log:\n",
    "            wandb.log({'Samples from posterior':fig})\n",
    "            \n",
    "        fig = plot_pytorch_images(x_hr, num_images=5, title='x_hr, num epochs: {}'.format(n))\n",
    "        if log:\n",
    "            wandb.log({'X high res':fig})\n",
    "        dsvae.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsvae.eval()\n",
    "y = torch.distributions.Normal(0,1).sample(torch_dataset[0:100].shape)\n",
    "x_hat, z_mu, z_var = dsvae(y.to(device), torch_dataset[0:100].to(device))\n",
    "\n",
    "from IPython.display import clear_output\n",
    "for z in np.linspace(z_mu[99].detach().cpu().numpy(),z_mu[77].detach().cpu().numpy()):\n",
    "    clear_output(wait=True)\n",
    "    z = torch.from_numpy(z).unsqueeze(0).to(device)\n",
    "    x_hat = dsvae.decode(torch.distributions.Normal(0,1).sample((1,3,128,128)).to(device), z)\n",
    "    plot_pytorch_images(x_hat, num_images=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsvae.eval()\n",
    "y = torch.distributions.Normal(0,1).sample(torch_dataset[0:5].shape)\n",
    "x_hat, z_mu, z_var = dsvae(y.to(device), torch_dataset[0:5].to(device))\n",
    "\n",
    "from scipy.stats import norm\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(18,5))\n",
    "idx = 4\n",
    "x_axis = np.arange(-5, 5, 0.001)\n",
    "for idx in range(0,5):\n",
    "    ax = axes[idx]\n",
    "    for i, mu in enumerate(z_mu[idx]):\n",
    "        ax.plot(x_axis, norm.pdf(x_axis, mu.detach().cpu().numpy(), torch.sqrt(z_var[idx][i]).detach().cpu().numpy()), alpha=.5)\n",
    "    ax.plot(x_axis, norm.pdf(x_axis, 0,1))\n",
    "    if idx > 0:\n",
    "        ax.set_yticks([],[])\n",
    "plt.show()\n",
    "plot_pytorch_images(x_hat, num_images=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsvae.eval()\n",
    "y = torch.distributions.Normal(0,1).sample(torch_dataset[0:5].shape)\n",
    "x_hat, z_mu, z_var = dsvae(y.to(device), torch_dataset[0:5].to(device))\n",
    "plot_pytorch_images(x_hat, num_images=5);\n",
    "noise = torch.distributions.Normal(0, 1).sample((5,3,128,128)).to(device)\n",
    "x_hat_sample = dsvae.decode(noise, torch.distributions.Normal(z_mu, z_var).sample())\n",
    "plot_pytorch_images(x_hat, num_images=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsvae.eval()\n",
    "dsvae.cpu()\n",
    "dsvae.device = None\n",
    "y = torch.distributions.Normal(0,1).sample(torch_dataset[:1000].shape)\n",
    "x_hr_hat, z_mu, z_var = dsvae(y, torch_dataset[:1000])\n",
    "z_sample = torch.distributions.Normal(z_mu, z_var).sample()\n",
    "z_sample_avg = torch.mean(z_sample, 0)\n",
    "z_sample_std = torch.std(z_sample, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(85), z_sample_avg.detach().cpu().numpy())\n",
    "plt.scatter(range(85), z_sample_std.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = z_sample_avg.detach()\n",
    "std = z_sample_std.detach()\n",
    "\n",
    "x_hat = dsvae.decode(torch.distributions.Normal(0,1).sample((1,3,128,128)), torch.distributions.Normal(mu, std).sample())\n",
    "plot_pytorch_images(x_hat.to(device), num_images=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(torch.distributions.Normal(0,1).sample((1,100))[0],bins=30)\n",
    "mu = torch.mean(z_sample_avg).detach().cpu()\n",
    "std = torch.mean(z_sample_std.detach()).cpu()\n",
    "plt.hist(torch.distributions.Normal(mu,std).sample((1,100))[0], bins=30);\n",
    "print(torch.distributions.kl_divergence(torch.distributions.Normal(mu,std), torch.distributions.Normal(0,1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
