{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, 'models')\n",
    "sys.path.insert(0, 'utils')\n",
    "import celeba\n",
    "import numpy as np\n",
    "import wandb\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import argparse\n",
    "from plotting_utils import plot_pytorch_images\n",
    "\n",
    "from vae_model_upsample import UPSAMPLE_VAE, loss_function\n",
    "from datasets import VAE_DATA\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--num_datapoints\", help=\"num datapoints\", default=10000, type=int)\n",
    "parser.add_argument(\"--validation_size\", help=\"Validation set size\", default=2000, type=int)\n",
    "parser.add_argument(\"--resolution\", help=\"num datapoints\", default=128, type=int)\n",
    "parser.add_argument(\"--z_dim\", help=\"z dimension\", default=85, type=int)\n",
    "parser.add_argument(\"--device\", help=\"gpu id\", default=0, type=int)\n",
    "parser.add_argument(\"--nb_epochs\", help=\"number of epochs\", default=500, type=int)\n",
    "parser.add_argument(\"--start_epoch\", help=\"epoch to start training from (requires checkpoints)\", default=0, type=int)\n",
    "parser.add_argument(\"--save_interval\", help=\"epochs to save model\", default=10, type=int)\n",
    "parser.add_argument(\"--run_seed\", help=\"run seed of TCVAE\", default=100, type=int)\n",
    "parser.add_argument(\"--lr\", help=\"learning rate\", default=.0001, type=float)\n",
    "parser.add_argument(\"--batch_size\", help=\"batch size\", default=100, type=int)\n",
    "parser.add_argument(\"--has_validation\", help=\"If True, will use validation set\", default=True, type=bool)\n",
    "args = parser.parse_args([])\n",
    "\n",
    "num_datapoints = args.num_datapoints\n",
    "resolution = args.resolution\n",
    "\n",
    "log = True\n",
    "if log:\n",
    "    wandb.init(project=\"upsample_vae\", name=\"celeba_{}_{}x{}\".format(num_datapoints, resolution, resolution))\n",
    "    wandb.config.update(args)\n",
    "\n",
    "device = args.device\n",
    "print(\"z_dim: {}\".format(args.z_dim))\n",
    "print(\"GPU: {}\".format(device))\n",
    "print(\"start_epoch: {}\".format(args.start_epoch))\n",
    "print(\"save_interval: {}\".format(args.save_interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 0\n",
    "if args.has_validation:\n",
    "    validation_size = args.validation_size\n",
    "num_samples = num_datapoints + validation_size\n",
    "if resolution > 128:\n",
    "    raise ValueError(\"Not that big\")\n",
    "dta = celeba.CelebA(\"../dsvae/yukun_disentanglement_lib/img_align_celeba\", num_samples, resolution)\n",
    "inputs = np.float32(dta.images[:num_datapoints])\n",
    "torch_inputs = torch.from_numpy(inputs).permute(0,3,1,2)\n",
    "torch_dataset = VAE_DATA(torch_inputs)\n",
    "torch_data_loader = torch.utils.data.DataLoader(torch_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "if args.has_validation:\n",
    "    val_inputs = np.float32(dta.images[num_datapoints:])\n",
    "    torch_val_inputs = torch.from_numpy(val_inputs).permute(0,3,1,2)\n",
    "    torch_val_dataset = VAE_DATA(torch_val_inputs)\n",
    "    torch_val_data_loader = torch.utils.data.DataLoader(torch_val_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "del dta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiating and Training VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=[3,resolution,resolution]\n",
    "upsample_from_shape = [3,64,64]\n",
    "if device != -1 and device is not None:\n",
    "    vae = UPSAMPLE_VAE(args.z_dim, input_shape, upsample_from_shape, device=device)\n",
    "    vae.to(device)\n",
    "else:\n",
    "    vae = UPSAMPLE_VAE(args.z_dim, input_shape, upsample_from_shape, device=None)\n",
    "optimizer = torch.optim.Adam(params=vae.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vae.train()\n",
    "normal = torch.distributions.Normal(0,1)\n",
    "print(\"Training for {} epochs...\".format(1500))\n",
    "for n in range(0, 1500):\n",
    "    train_loss = 0\n",
    "    train_recon_loss = 0\n",
    "    train_kl_loss = 0\n",
    "    num_examples = 0\n",
    "    for (i, X) in enumerate(torch_data_loader):\n",
    "        x = X\n",
    "        if vae.cuda:\n",
    "            x = x.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x_hat, z_mu, z_var = vae(x)\n",
    "        loss, recon_loss, kl_loss = loss_function(x_hat, x, z_mu, z_var)\n",
    "        train_loss += loss.item()\n",
    "        train_recon_loss += recon_loss.item()\n",
    "        train_kl_loss += kl_loss.item()\n",
    "        num_examples += x_hat.shape[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if log:\n",
    "        wandb.log({'train_loss':train_loss/num_examples})\n",
    "        wandb.log({'train_recon_loss':train_recon_loss/num_examples})\n",
    "        wandb.log({'train_kl_loss':train_kl_loss/num_examples})\n",
    "        \n",
    "    if args.has_validation:\n",
    "        val_loss = 0\n",
    "        val_recon_loss = 0\n",
    "        val_kl_loss = 0\n",
    "        num_examples = 0\n",
    "        for (i, X) in enumerate(torch_val_data_loader):\n",
    "            x_val = X\n",
    "            if vae.cuda:\n",
    "                x_val = x_val.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            x_hat_val, z_mu, z_var = vae(x_val)\n",
    "            loss, recon_loss, kl_loss = loss_function(x_hat_val, x_val, z_mu, z_var)\n",
    "            val_loss += loss.item()\n",
    "            val_recon_loss += recon_loss.item()\n",
    "            val_kl_loss += kl_loss.item()\n",
    "            num_examples += x_hat_val.shape[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if log:\n",
    "            wandb.log({'val_loss':val_loss/num_examples})\n",
    "            wandb.log({'val_recon_loss':val_recon_loss/num_examples})\n",
    "            wandb.log({'val_kl_loss':val_kl_loss/num_examples})\n",
    "        \n",
    "    if n%10 ==0:\n",
    "        vae.eval() #evaluate model\n",
    "        z_noise = normal.sample((x.shape[0],85))\n",
    "        z_zeros = torch.zeros((x.shape[0],85))\n",
    "        if vae.cuda:\n",
    "            z_noise = z_noise.to(device)\n",
    "            z_zeros = z_zeros.to(device)\n",
    "        x_hat_noise = vae.decode(z_noise)\n",
    "        x_hat_zeros = vae.decode(z_zeros)\n",
    "\n",
    "        fig = plot_pytorch_images(x_hat_noise[:5], num_images=5, title='Samples from prior, num epochs: {}'.format(n))\n",
    "        if log:\n",
    "            wandb.log({'Samples from prior':fig})\n",
    "            \n",
    "        fig = plot_pytorch_images(x_hat[:5], num_images=5, title='Means of posterior train x, num epochs: {}'.format(n))\n",
    "        if log:\n",
    "            wandb.log({'Means of posterior train x':fig})\n",
    "            \n",
    "        fig = plot_pytorch_images(x[:5], num_images=5, title='train x, num epochs: {}'.format(n))\n",
    "        if log:\n",
    "            wandb.log({'train x':fig})\n",
    "        \n",
    "        if args.has_validation:\n",
    "            x_val = torch_val_dataset[np.random.choice(range(len(torch_val_dataset)), size=5, replace=False)]\n",
    "            if vae.cuda:\n",
    "                x_val = x_val.to(device)\n",
    "            x_val_hat, _, _ = vae(x_val)\n",
    "            fig = plot_pytorch_images(x_val_hat[:5], num_images=5, title='Means of posterior val x, num epochs: {}'.format(n))\n",
    "            if log:\n",
    "                wandb.log({'Means of posterior val x':fig})\n",
    "\n",
    "            fig = plot_pytorch_images(x_val[:5], num_images=5, title='val x, num epochs: {}'.format(n))\n",
    "            if log:\n",
    "                wandb.log({'val x':fig})\n",
    "\n",
    "        vae.train() #back to training model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
